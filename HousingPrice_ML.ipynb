{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acbe8c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Imports You Might Need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn import ensemble\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Extract Dataset\n",
    "with zipfile.ZipFile('cook_county_contest_data.zip') as item:\n",
    "    item.extractall()\n",
    "from sklearn import linear_model as lm\n",
    "import torch\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.client import device_lib \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB     # 从sklean.naive_bayes里导入朴素贝叶斯模型\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import tensorflow as tf\n",
    "#print('Tensorflow Version: {}'.format(tf.__version__))\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]='2'# 只显示 Error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from random import seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b48c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def add_total_bedrooms(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing at least the Description column.\n",
    "    \"\"\"\n",
    "    with_rooms = data.copy()\n",
    "    pattern = r'(\\d+)(.\\d+)? of which (are|is) (bedrooms|bedroom)'\n",
    "    with_rooms['Bedrooms'] = with_rooms['Description'].apply(lambda x: int(re.findall(pattern, x)[0][0]) if len(re.findall(pattern, x))>0 else np.nan)\n",
    "    with_rooms.fillna(0)\n",
    "    return with_rooms\n",
    "\n",
    "def ohe_roof_material(data):\n",
    "    \"\"\"\n",
    "    One-hot-encodes roof material.  New columns are of the form 0x_QUALITY.\n",
    "    \"\"\"\n",
    "    ohe = OneHotEncoder()\n",
    "    new_columns = pd.DataFrame(data=ohe.fit_transform(data[['Roof Material']]).todense(), \n",
    "                              columns=ohe.get_feature_names(),\n",
    "                             index = data.index)\n",
    "    return data.join(new_columns)\n",
    "\n",
    "def substitute_roof_material(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a 'Roof Material' column.  Its values\n",
    "                         should be limited to those found in the codebook\n",
    "    Output:\n",
    "      data frame identical to the input except with a refactored 'Roof Material' column\n",
    "    \"\"\"\n",
    "    dictionary = {1:'Shingle/Asphalt', 2:'Tar&Gravel', 3:'Slate', 4:'Shake', 5:'Tile', 6:'Other'}\n",
    "    data['Roof Material'] = data['Roof Material'].replace(dictionary)\n",
    "    return data\n",
    "  \n",
    "def process_data_gm(data, pipeline_functions, prediction_col):\n",
    "    \"\"\"Process the data for a guided model.\"\"\"\n",
    "    for function, arguments, keyword_arguments in pipeline_functions:\n",
    "        if keyword_arguments and (not arguments):\n",
    "            data = data.pipe(function, **keyword_arguments)\n",
    "        elif (not keyword_arguments) and (arguments):\n",
    "            data = data.pipe(function, *arguments)\n",
    "        else:\n",
    "            data = data.pipe(function)\n",
    "    X = data.drop(columns=[prediction_col]).to_numpy()\n",
    "    y = data.loc[:, prediction_col].to_numpy()\n",
    "    return X, y\n",
    "\n",
    "def add_in_expensive_neighborhood(data, neighborhoods):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a 'Neighborhood Code' column with values\n",
    "        found in the codebook\n",
    "      neighborhoods (list of strings): strings should be the names of neighborhoods\n",
    "        pre-identified as rich\n",
    "    Output:\n",
    "      data frame identical to the input with the addition of a binary\n",
    "      in_rich_neighborhood column\n",
    "    \"\"\"\n",
    "    data['in_expensive_neighborhood'] = data['Neighborhood Code'].isin(neighborhoods).astype(int)\n",
    "    return data\n",
    "\n",
    "def find_expensive_neighborhoods(data, n=3, metric=np.median):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): should contain at least a string-valued Neighborhood\n",
    "        and a numeric 'Sale Price' column\n",
    "      n (int): the number of top values desired\n",
    "      metric (function): function used for aggregating the data in each neighborhood.\n",
    "        for example, np.median for median prices\n",
    "    \n",
    "    Output:\n",
    "      a list of the top n richest neighborhoods as measured by the metric function\n",
    "    \"\"\"\n",
    "    neighborhoods = data.groupby('Neighborhood Code').agg({'Log Sale Price':metric}).sort_values('Log Sale Price',ascending=False).head(n).index\n",
    "    \n",
    "    # This makes sure the final list contains the generic int type used in Python3, not specific ones used in numpy.\n",
    "    return [int(code) for code in neighborhoods]\n",
    "\n",
    "def select_columns(data, *columns):\n",
    "    \"\"\"Select only columns passed as arguments.\"\"\"\n",
    "    return data.loc[:, columns]\n",
    "\n",
    "def rmse(predicted, actual):\n",
    "    return np.sqrt(np.mean((actual - predicted)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ec5fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_fm(data):\n",
    "    X = data\n",
    "    X['Log Building Square Feet'] = np.log(X['Building Square Feet'])\n",
    "    X = add_total_bedrooms(X)\n",
    "    X = substitute_roof_material(X)\n",
    "    X = ohe_roof_material(X)\n",
    "    X = select_columns(X, 'Bedrooms','Property Class', 'Log Building Square Feet', 'x0_Other', 'x0_Shake', 'x0_Shingle/Asphalt',\n",
    "                       'x0_Slate', 'x0_Tar&Gravel', 'x0_Tile','Age', 'Apartments')\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af60a821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e578905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('cook_county_contest_data/cook_county_contest_train.csv')\n",
    "y_train = np.log(train_data['Sale Price'])\n",
    "X_train = process_data_fm(train_data)\n",
    "size, features = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445ff218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ab99c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fb888a8",
   "metadata": {},
   "source": [
    "## 3-Layer MLP, 50 epoches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "739e8b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(features, ))\n",
    "hidden = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "hidden = tf.keras.layers.Dense(64, activation='relu')(hidden)\n",
    "hidden = tf.keras.layers.Dense(64, activation='relu')(hidden)\n",
    "outputs = tf.keras.layers.Dense(1, activation='linear')(hidden)\n",
    "\n",
    "tf_model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67d186df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3801/3801 [==============================] - 11s 3ms/step - loss: 0.4637 - val_loss: 0.4412\n",
      "Epoch 2/50\n",
      "3801/3801 [==============================] - 11s 3ms/step - loss: 0.4630 - val_loss: 0.4487\n",
      "Epoch 3/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4596 - val_loss: 0.4488\n",
      "Epoch 4/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4625 - val_loss: 0.4456\n",
      "Epoch 5/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4608 - val_loss: 0.4421\n",
      "Epoch 6/50\n",
      "3801/3801 [==============================] - 9s 2ms/step - loss: 0.4574 - val_loss: 0.4508\n",
      "Epoch 7/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4595 - val_loss: 0.4434\n",
      "Epoch 8/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4581 - val_loss: 0.4479\n",
      "Epoch 9/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4575 - val_loss: 0.4421\n",
      "Epoch 10/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4570 - val_loss: 0.4810\n",
      "Epoch 11/50\n",
      "3801/3801 [==============================] - 11s 3ms/step - loss: 0.4564 - val_loss: 0.4475\n",
      "Epoch 12/50\n",
      "3801/3801 [==============================] - 11s 3ms/step - loss: 0.4563 - val_loss: 0.4517\n",
      "Epoch 13/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4559 - val_loss: 0.4511\n",
      "Epoch 14/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4586 - val_loss: 0.4405\n",
      "Epoch 15/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4544 - val_loss: 0.4429\n",
      "Epoch 16/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4564 - val_loss: 0.4494\n",
      "Epoch 17/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4548 - val_loss: 0.4538\n",
      "Epoch 18/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4559 - val_loss: 0.4471\n",
      "Epoch 19/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4552 - val_loss: 0.4461\n",
      "Epoch 20/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4568 - val_loss: 0.4420\n",
      "Epoch 21/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4552 - val_loss: 0.5528\n",
      "Epoch 22/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4552 - val_loss: 0.4442\n",
      "Epoch 23/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4547 - val_loss: 0.4415\n",
      "Epoch 24/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4548 - val_loss: 0.4512\n",
      "Epoch 25/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4544 - val_loss: 0.4812\n",
      "Epoch 26/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4533 - val_loss: 0.4439\n",
      "Epoch 27/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4546 - val_loss: 0.4437\n",
      "Epoch 28/50\n",
      "3801/3801 [==============================] - 11s 3ms/step - loss: 0.4534 - val_loss: 0.4651\n",
      "Epoch 29/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4528 - val_loss: 0.4505\n",
      "Epoch 30/50\n",
      "3801/3801 [==============================] - 11s 3ms/step - loss: 0.4528 - val_loss: 0.4413\n",
      "Epoch 31/50\n",
      "3801/3801 [==============================] - 11s 3ms/step - loss: 0.4529 - val_loss: 0.4412\n",
      "Epoch 32/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4521 - val_loss: 0.4705\n",
      "Epoch 33/50\n",
      "3801/3801 [==============================] - 11s 3ms/step - loss: 0.4525 - val_loss: 0.4821\n",
      "Epoch 34/50\n",
      "3801/3801 [==============================] - 11s 3ms/step - loss: 0.4525 - val_loss: 0.4478\n",
      "Epoch 35/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4532 - val_loss: 0.4443\n",
      "Epoch 36/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4523 - val_loss: 0.4441\n",
      "Epoch 37/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4519 - val_loss: 0.4400\n",
      "Epoch 38/50\n",
      "3801/3801 [==============================] - 9s 2ms/step - loss: 0.4534 - val_loss: 0.4452\n",
      "Epoch 39/50\n",
      "3801/3801 [==============================] - 9s 2ms/step - loss: 0.4526 - val_loss: 0.4427\n",
      "Epoch 40/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4520 - val_loss: 0.4554\n",
      "Epoch 41/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4514 - val_loss: 0.4429\n",
      "Epoch 42/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4513 - val_loss: 0.4410\n",
      "Epoch 43/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4514 - val_loss: 0.4456\n",
      "Epoch 44/50\n",
      "3801/3801 [==============================] - 9s 2ms/step - loss: 0.4507 - val_loss: 0.4398\n",
      "Epoch 45/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4507 - val_loss: 0.4394\n",
      "Epoch 46/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4514 - val_loss: 0.4433\n",
      "Epoch 47/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4517 - val_loss: 0.4403\n",
      "Epoch 48/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4516 - val_loss: 0.4535\n",
      "Epoch 49/50\n",
      "3801/3801 [==============================] - 9s 2ms/step - loss: 0.4526 - val_loss: 0.4455\n",
      "Epoch 50/50\n",
      "3801/3801 [==============================] - 10s 3ms/step - loss: 0.4501 - val_loss: 0.4413\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "tf_model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'mse'\n",
    ")\n",
    "\n",
    "history = tf_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.12,\n",
    "    batch_size=32,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03ec8183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('cook_county_contest_test.csv')\n",
    "X_test = process_data_fm(test_data)\n",
    "tf_predicted = tf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b9b287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.read_csv(\"saleprice.csv\")\n",
    "answer = answer.drop(\"Unnamed: 0\",axis=1)\n",
    "answer['log_price'] = np.log(answer['Sale Price'])\n",
    "answer['log_tf_predicted'] = tf_predicted\n",
    "answer['tf_predicted'] = np.exp(tf_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "817a15b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133496.70923810574"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(answer['Sale Price'],answer['tf_predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f74e31b",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd033889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = ensemble.RandomForestRegressor()\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5f421cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136399.4385239601"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_predicted = rf_model.predict(X_test)\n",
    "answer['rf_predicted'] = rf_predicted\n",
    "answer['rf_predicted'] = np.exp(rf_predicted)\n",
    "rmse(answer['Sale Price'],answer['rf_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8dfbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(answer['log_price'], answer['lr_predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5bb3d6",
   "metadata": {},
   "source": [
    "## Simple Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5b618a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "138a2495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVR(C=0.01, epsilon=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVR</label><div class=\"sk-toggleable__content\"><pre>LinearSVR(C=0.01, epsilon=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVR(C=0.01, epsilon=5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 5\n",
    "svr = LinearSVR(epsilon=eps, C=0.01, fit_intercept=True)\n",
    "svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b401a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267355.8661293371"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_predicted = svr.predict(X_test)\n",
    "answer['log_svr_predicted'] = svr_predicted\n",
    "answer['svr_predicted'] = np.exp(svr_predicted)\n",
    "rmse(answer['Sale Price'],answer['svr_predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaa2d4f",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fac87b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47371cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138217, 11)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4f60ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(LSTM(32, return_sequences = True))\n",
    "lstm.add(LSTM(16))\n",
    "lstm.add(Dense(1))\n",
    "lstm.add(Activation('linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c986277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\zihen\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\zihen\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\zihen\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\zihen\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\zihen\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\zihen\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_7\" (type Sequential).\n    \n    Input 0 of layer \"lstm_12\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (1, 11)\n    \n    Call arguments received by layer \"sequential_7\" (type Sequential):\n      • inputs=tf.Tensor(shape=(1, 11), dtype=float64)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m lstm\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madagrad\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Try SGD, adam, adagrad and compare\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mlstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filexqkdb7oh.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\zihen\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\zihen\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\zihen\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\zihen\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\zihen\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\zihen\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_7\" (type Sequential).\n    \n    Input 0 of layer \"lstm_12\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (1, 11)\n    \n    Call arguments received by layer \"sequential_7\" (type Sequential):\n      • inputs=tf.Tensor(shape=(1, 11), dtype=float64)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "lstm.compile(loss='mean_squared_error', optimizer='adagrad') # Try SGD, adam, adagrad and compare\n",
    "lstm.fit(X_train, y_train, epochs=5, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982919f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
